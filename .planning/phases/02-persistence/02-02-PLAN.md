---
phase: 02-persistence
plan: 02
type: tdd
depends_on: ["02-01"]
files_modified: [src/persistence/database/schema.ts, src/persistence/database/migrations/0001_add_episodes.sql, src/persistence/memory/MemorySystem.ts, src/persistence/memory/MemorySystem.test.ts, src/persistence/memory/EmbeddingsService.ts, src/persistence/memory/EmbeddingsService.test.ts]
---

<objective>
Implement MemorySystem and EmbeddingsService using TDD for episodic memory with embedding-based search.

Purpose: Provide long-term memory for agents to recall relevant past experiences (code generation, error fixes, decisions) using semantic similarity search.
Output: Working memory system that stores episodes with embeddings and retrieves relevant context.
</objective>

<execution_context>
./.claude/get-shit-done/workflows/execute-plan.md
./.planning/phases/02-persistence/summary.md
./.claude/get-shit-done/references/tdd.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-persistence/02-01-SUMMARY.md

# Database schema:
@src/persistence/database/schema.ts
@src/persistence/database/DatabaseClient.ts

# Reference implementations:
@src/infrastructure/file-system/FileSystemService.ts

**Tech stack available:** TypeScript 5.9+, Drizzle ORM, better-sqlite3, Vitest, zod
**Established patterns:**
- TDD red-green-refactor
- Error hierarchy with Object.setPrototypeOf
- Drizzle ORM for database operations

**Constraining decisions:**
- Use OpenAI text-embedding-3-small for embeddings (1536 dimensions)
- Store embeddings as JSON blob in SQLite (no vector extension needed for small scale)
- Cosine similarity for search
</context>

<feature>
  <name>MemorySystem + EmbeddingsService</name>
  <files>src/persistence/database/schema.ts, src/persistence/memory/MemorySystem.ts, src/persistence/memory/MemorySystem.test.ts, src/persistence/memory/EmbeddingsService.ts, src/persistence/memory/EmbeddingsService.test.ts</files>
  <behavior>
**Master Book Reference:** BUILD-006 (Section 4.3)

## Schema Migration (Pre-requisite)

Add episodes table to schema:

```typescript
export const episodes = sqliteTable('episodes', {
  id: text('id').primaryKey(),
  projectId: text('project_id')
    .notNull()
    .references(() => projects.id, { onDelete: 'cascade' }),
  type: text('type')
    .$type<'code_generation' | 'error_fix' | 'review_feedback' | 'decision' | 'research'>()
    .notNull(),
  content: text('content').notNull(),
  summary: text('summary'), // Short summary for display
  embedding: text('embedding'), // JSON array of floats (1536 dimensions)
  context: text('context'), // JSON metadata
  taskId: text('task_id'),
  agentId: text('agent_id'),
  importance: real('importance').default(1.0), // For pruning priority
  accessCount: integer('access_count').default(0),
  lastAccessedAt: integer('last_accessed_at', { mode: 'timestamp' }),
  createdAt: integer('created_at', { mode: 'timestamp' }).notNull(),
});
```

## EmbeddingsService

Generates embeddings using OpenAI API with local caching.

**Core behaviors to test:**

1. **Custom Error Types:**
   - EmbeddingsError base class
   - EmbeddingAPIError with statusCode and message
   - CacheError with reason

2. **Embedding Generation:**
   - embed(text: string) returns number[] (1536 floats)
   - embed caches result by content hash
   - embed returns cached result on cache hit
   - embedBatch(texts: string[]) returns number[][] for multiple texts
   - embedBatch uses single API call for efficiency

3. **Cache Management:**
   - Cache stored in SQLite (separate embeddings_cache table or in-memory Map)
   - clearCache() removes all cached embeddings
   - getCacheStats() returns hit/miss counts

4. **API Integration:**
   - Uses OpenAI text-embedding-3-small model
   - Handles rate limiting with exponential backoff
   - Throws EmbeddingAPIError on API failures
   - Supports mock mode for testing (returns deterministic fake embeddings)

5. **Constructor:**
   - Accepts OpenAI API key (from environment or config)
   - Accepts optional cache configuration
   - Accepts optional logger

## MemorySystem

Stores and retrieves episodic memories using semantic similarity.

**Core behaviors to test:**

1. **Custom Error Types:**
   - MemoryError base class
   - EpisodeNotFoundError with episodeId
   - QueryError with reason

2. **Episode Storage:**
   - storeEpisode(episode: EpisodeInput) stores episode with auto-generated embedding
   - storeEpisode returns Episode with id
   - storeEpisode handles embedding generation failure gracefully (stores without embedding)
   - storeEpisode extracts summary if not provided (first 200 chars)

3. **Memory Query:**
   - queryMemory(query: string, limit?: number) returns Episode[] sorted by relevance
   - queryMemory uses cosine similarity between query embedding and stored embeddings
   - queryMemory returns empty array if no memories
   - queryMemory updates accessCount and lastAccessedAt on returned episodes
   - queryMemory respects limit (default 10)

4. **Context Retrieval:**
   - getRelevantContext(taskId: string, maxTokens: number) builds context string
   - getRelevantContext includes task-related episodes first
   - getRelevantContext fills remaining space with relevant memories
   - getRelevantContext respects token limit (approximate by character count / 4)

5. **Pruning:**
   - pruneOldEpisodes(maxAge: number) removes episodes older than maxAge
   - pruneOldEpisodes returns count of deleted episodes
   - pruneOldEpisodes respects importance (high importance episodes kept longer)
   - pruneByCount(maxCount: number) keeps only most recent/important episodes

6. **Constructor:**
   - Accepts database client, EmbeddingsService
   - Accepts optional logger
   - Accepts optional projectId scope

**Cosine Similarity Implementation:**
```typescript
function cosineSimilarity(a: number[], b: number[]): number {
  let dotProduct = 0;
  let normA = 0;
  let normB = 0;
  for (let i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}
```

**Input/Output Examples:**

```typescript
// Store episode
const episode = await memory.storeEpisode({
  type: 'code_generation',
  content: 'Created UserService with JWT authentication and bcrypt password hashing',
  context: { taskId: 'task-001', files: ['src/services/UserService.ts'] }
});
// Returns: { id: 'ep-123', type: 'code_generation', ... }

// Query memory
const results = await memory.queryMemory('authentication', 5);
// Returns top 5 episodes semantically similar to "authentication"

// Get context for task
const context = await memory.getRelevantContext('task-002', 4000);
// Returns: "Previous relevant work:\n- Created UserService with JWT...\n- ..."
```
  </behavior>
  <implementation>
**RED Phase:**
1. First, add episodes table to schema and generate migration
2. Write failing tests for EmbeddingsService (mock OpenAI API)
3. Write failing tests for MemorySystem

**GREEN Phase:**

1. **Schema Migration:**
   - Add episodes table to schema.ts
   - Run `pnpm drizzle-kit generate` to create migration
   - Update relations

2. **EmbeddingsService:**
   - Use fetch for OpenAI API calls (no SDK needed)
   - Cache in Map<string, number[]> keyed by SHA-256 hash of content
   - Implement exponential backoff: 1s, 2s, 4s, 8s, max 3 retries
   - Mock mode: return array of 1536 zeros with content hash influence

3. **MemorySystem:**
   - Use Drizzle ORM for episode CRUD
   - Implement cosineSimilarity as utility function
   - Sort results by similarity score descending
   - Token estimation: chars / 4 (rough GPT tokenizer approximation)

**REFACTOR Phase:**
- Extract similarity search to reusable utility
- Consider batch embedding for bulk episode storage
  </implementation>
</feature>

<verification>
- [ ] Schema migration generated and applies cleanly
- [ ] `pnpm test -- persistence/memory` passes all tests
- [ ] `pnpm typecheck` passes
- [ ] `pnpm lint` passes
- [ ] Coverage >= 80% for MemorySystem and EmbeddingsService
- [ ] Memory queries return relevant results (semantic similarity works)
</verification>

<success_criteria>
- Episodes table added to schema with migration
- Failing tests written and committed (RED)
- Implementation passes all tests (GREEN)
- Refactor complete if needed
- Embedding generation works (mocked in tests)
- Memory query returns semantically similar episodes
</success_criteria>

<output>
After completion, create `.planning/phases/02-persistence/02-02-SUMMARY.md` with:
- RED: What tests were written, why they failed
- GREEN: What implementation made them pass
- REFACTOR: What cleanup was done (if any)
- Commits: List of commits produced
</output>
